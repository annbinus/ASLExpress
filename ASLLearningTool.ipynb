{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/annbinus/ASLExpress/blob/akhila's-branch/ASLLearningTool.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "LLuc7hRlbDyK"
      },
      "outputs": [],
      "source": [
        "#pip install --upgrade mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install english-words"
      ],
      "metadata": {
        "id": "Wm6altGtw1e8"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Import the OpenCV library for computer vision tasks.\n",
        "import cv2 as cv\n",
        "\n",
        "# Import the Mediapipe library for various computer vision and machine learning tasks.\n",
        "import mediapipe as mp\n",
        "\n",
        "# Import the joblib library for saving and loading machine learning models.\n",
        "import joblib\n",
        "\n",
        "# Import the time module for time-related operations or measurements.\n",
        "import time\n",
        "\n",
        "# Import the os and sys modules for operating system and system-related functions.\n",
        "import os, sys"
      ],
      "metadata": {
        "id": "3rTkQzRlmDf3"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from random import random"
      ],
      "metadata": {
        "id": "Ai2_cJ2LpfiS"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the function 'get_english_words_set' from the 'english_words' library.\n",
        "from english_words import get_english_words_set\n",
        "\n",
        "# Create a set of English words from the 'web2' dataset in lowercase.\n",
        "# The 'get_english_words_set' function is used with the 'lower' parameter set to 'True'\n",
        "# to ensure that the words are converted to lowercase.\n",
        "web2lowerset = get_english_words_set(['web2'], lower=True)"
      ],
      "metadata": {
        "id": "u8owAuRRqD7k"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary modules from the Flask framework\n",
        "from flask import Flask           # Flask is used to create the web application instance.\n",
        "from flask import render_template # render_template is used to render HTML templates.\n",
        "from flask import Response        # Response is used to create HTTP responses.\n",
        "from flask import request         # request is used to access data sent with HTTP requests."
      ],
      "metadata": {
        "id": "kMDiPqf6qGiF"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Global Variables for Game Difficulty and Mode\n",
        "global easy, medium, hard, freestyle, switch\n",
        "level1 = 0        # Represents the easy game mode.\n",
        "level2 = 0      # Represents the medium game mode.\n",
        "level3 = 0        # Represents the hard game mode.\n",
        "freestyle = 0   # Represents the freestyle game mode."
      ],
      "metadata": {
        "id": "phGTAZ-6rnVF"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a pre-trained machine learning model (Random Forest Classifier) from a file named \"random_forest.joblib\"\n",
        "clf = joblib.load(\"/content/random_forest.joblib\")"
      ],
      "metadata": {
        "id": "7DK8wJbcrnXl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e1b3190-8e30-43fb-ef18-50e46ae326fb"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.24.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.24.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "app = Flask(__name__, template_folder='./template')"
      ],
      "metadata": {
        "id": "x4j8pW7evA1o"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to perform object detection using a provided model.\n",
        "# Args:\n",
        "#   image (numpy.ndarray): Input image in BGR format.\n",
        "#   model: A pre-trained machine learning model (e.g., Mediapipe model).\n",
        "# Returns:\n",
        "#   image (numpy.ndarray): Processed image in BGR format.\n",
        "#   results: Detection results from the model.\n",
        "def mediapipe_detection(image, model):\n",
        "    # Convert the input image from BGR to RGB color space.\n",
        "    image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
        "\n",
        "    # Make predictions using the provided model.\n",
        "    final_results = model.process(image)\n",
        "\n",
        "    # Convert the processed image from RGB back to BGR color space.\n",
        "    image = cv.cvtColor(image, cv.COLOR_RGB2BGR)\n",
        "\n",
        "    # Return the processed image and detection results.\n",
        "    return image, final_results"
      ],
      "metadata": {
        "id": "GgtWaNnvywgS"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate and return the normalized landmark distances relative to the wrist position.\n",
        "# Args:\n",
        "#   results: Detection results containing hand landmarks.\n",
        "#   frame_width (int): Width of the frame or image.\n",
        "#   frame_height (int): Height of the frame or image.\n",
        "# Returns:\n",
        "#   normalized_landmark_distances (list): List of normalized landmark distances (x and y coordinates).\n",
        "def get_normalized_landmark_distances(results, frame_width, frame_height):\n",
        "    normalized_landmark_distances = []  # Initialize an empty list to store normalized landmark distances.\n",
        "\n",
        "    # Get the wrist position (the reference point) of the detected hand.\n",
        "    wrist_position = results.multi_hand_landmarks[0].landmark[0]\n",
        "\n",
        "    # Calculate and normalize the distances of each landmark relative to the wrist position.\n",
        "    for landmark in results.multi_hand_landmarks[0].landmark:\n",
        "        # Calculate and normalize the x and y distances based on the frame width and height.\n",
        "        normalized_x = (landmark.x - wrist_position.x) * (frame_width / frame_width)\n",
        "        normalized_y = (landmark.y - wrist_position.y) * (frame_height / frame_height)\n",
        "\n",
        "        # Append the normalized distances to the normalized_landmark_distances list.\n",
        "        normalized_landmark_distances.append(normalized_x)\n",
        "        normalized_landmark_distances.append(normalized_y)\n",
        "\n",
        "    # Return the list of normalized landmark distances, excluding the wrist position (first two values).\n",
        "    return normalized_landmark_distances[2:]\n"
      ],
      "metadata": {
        "id": "M51vWTeBywlA"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to determine the maximum available camera index connected to the host device.\n",
        "# Returns the maximum camera index as an integer.\n",
        "\n",
        "def camera_max():\n",
        "    camera_index = 0  # Initialize the camera index to 0.\n",
        "\n",
        "    while True:\n",
        "        # Check if the camera with the current index can be accessed.\n",
        "        if cv.VideoCapture(camera_index).grab():\n",
        "            camera_index += 1\n",
        "        else:\n",
        "            # Close any open windows and return the maximum camera index (camera_index - 1).\n",
        "            cv.destroyAllWindows()\n",
        "            return max(0, int(camera_index - 1))\n"
      ],
      "metadata": {
        "id": "m8OJMHynywny"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list of words that are sorted, do not contain 'z', and have a length between 4 and 10 characters.\n",
        "words = [word for word in sorted(list(web2lowerset)) if 'z' not in word and 3 < len(word) <= 10]\n",
        "\n",
        "# Initialize some variables\n",
        "start_time = time.time()\n",
        "curr_time = 0\n",
        "user_input_word = ''\n",
        "eraser = 0\n",
        "\n",
        "# Choose a random word from the 'words' list and convert it to uppercase\n",
        "random_word = words[int(random() * len(words))].upper()\n",
        "random_word_index = 0\n",
        "\n",
        "# Create a list of lowercase letters\n",
        "letters = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
        "\n",
        "# Initialize video capture using the maximum available camera\n",
        "cap = cv.VideoCapture(camera_max())\n",
        "width = int(cap.get(cv.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "# Set up the MediaPipe hands model\n",
        "mp_hands = mp.solutions.hands\n",
        "with mp_hands.Hands(min_detection_confidence=0.6, min_tracking_confidence=0.6, max_num_hands=1) as hands:\n",
        "    while cap.isOpened():\n",
        "        # Read a frame from the camera\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "        try:\n",
        "            # Display the 'random_word' on the frame\n",
        "            cv.putText(frame, random_word, (int(width * 0.05), int(height * 0.95)), cv.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 2, cv.LINE_4)\n",
        "\n",
        "            # Display the 'user_input_word' on the frame\n",
        "            cv.putText(frame, user_input_word, (int(width * 0.05), int(height * 0.95)), cv.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 2, cv.LINE_4)\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "\n",
        "        # Make hand detections using MediaPipe\n",
        "        image, results = mediapipe_detection(frame, hands)\n",
        "\n",
        "        # Load an image of the letter corresponding to the current character in 'random_word'\n",
        "        letter_image = cv.resize(cv.imread('easy_mode_letters/{}.png'.format(random_word[random_word_index].lower())), (0, 0), fx=0.2, fy=0.2)\n",
        "\n",
        "        # Find the bounding box of the detected hand\n",
        "        if results.multi_hand_landmarks:\n",
        "            x = [None, None]\n",
        "            y = [None, None]\n",
        "            for result in results.multi_hand_landmarks[0].landmark:\n",
        "                if x[0] is None or result.x < x[0]:\n",
        "                    x[0] = result.x\n",
        "                if x[1] is None or result.x > x[1]:\n",
        "                    x[1] = result.x\n",
        "\n",
        "                if y[0] is None or result.y < y[0]:\n",
        "                    y[0] = result.y\n",
        "                if y[1] is None or result.y > y[1]:\n",
        "                    y[1] = result.y\n",
        "\n",
        "        # Check if the current time is less than one-third of the time elapsed since the start\n",
        "        if curr_time < round((time.time() - start_time) / 3, 1):\n",
        "            # Update current time with one-third of the elapsed time\n",
        "            curr_time = round((time.time() - start_time) / 3, 1)\n",
        "\n",
        "            try:\n",
        "                # Get landmark distances from a function\n",
        "                test_image = get_landmark_dist_test(results, x[1] - x[0], y[1] - y[0])\n",
        "\n",
        "                # Predict a class label using a machine learning classifier\n",
        "                test_pred = np.argmax(clf.predict_proba(np.array([test_image])))\n",
        "                test_probs = clf.predict_proba(np.array([test_image]))[0]\n",
        "\n",
        "                # Check if the maximum predicted probability is above a threshold or\n",
        "                # if it's moderately high and the predicted letter is 'r' or 'v'\n",
        "                if max(test_probs) >= 0.8 or (max(test_probs) >= 0.6 and letters[test_pred] in ['r', 'v']):\n",
        "                    pred_letter = letters[test_pred].upper()\n",
        "\n",
        "                    # Check if the predicted letter matches the expected letter in the word\n",
        "                    if easy_word_index < len(easy_word) and pred_letter == easy_word[easy_word_index] and (easy_word_index == 0 or easy_word[easy_word_index] != easy_word[easy_word_index - 1]):\n",
        "                        easy_word_user += pred_letter\n",
        "                        easy_word_index += 1\n",
        "                        location = results.multi_hand_landmarks[0].landmark[0].x\n",
        "\n",
        "                    # Check if the predicted letter matches the expected letter,\n",
        "                    # and if the previous and current letters are the same,\n",
        "                    # and if the hand location has changed significantly\n",
        "                    if easy_word_index < len(easy_word) and pred_letter == easy_word[easy_word_index] and easy_word_index > 0 and easy_word[easy_word_index] == easy_word[easy_word_index - 1] and abs(location - results.multi_hand_landmarks[0].landmark[0].x) > 0.1:\n",
        "                        easy_word_user += pred_letter\n",
        "                        easy_word_index += 1\n",
        "                        location = results.multi_hand_landmarks[0].landmark[0].x\n",
        "\n",
        "                # Check if the user has correctly spelled the word\n",
        "                if easy_word_user == easy_word:\n",
        "                    time.sleep(0.5)\n",
        "                    # Select a new random word and reset variables\n",
        "                    easy_word = words[int(random() * len(words))].upper()\n",
        "                    easy_word_index = 0\n",
        "                    easy_word_user = ''\n",
        "\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "\n",
        "        # Display an image on the screen\n",
        "        frame[5:5 + letter_help.shape[0], width - 5 - letter_help.shape[1]:width - 5] = letter_help\n",
        "        cv.imshow('OpenCV Feed', frame)\n",
        "\n",
        "        # Break the loop if the user presses the 'Esc' key\n",
        "        key = cv.waitKey(20)\n",
        "        if key == 27:\n",
        "            break\n",
        "\n",
        "# Release the video capture and close all OpenCV windows\n",
        "cap.release()\n",
        "cv.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "pEpWVKkL_EL_"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a list of lowercase letters\n",
        "letters = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
        "\n",
        "# Create a list of sorted words that do not contain 'z' and have a length between 4 and 10 characters\n",
        "words = [i for i in sorted(list(web2lowerset)) if 'z' not in i and len(i) > 3 and len(i) <= 10]\n",
        "\n",
        "# Initialize some variables\n",
        "start_time = time.time()\n",
        "curr_time = 0\n",
        "user_input_word = ''\n",
        "eraser = 0\n",
        "\n",
        "# Choose a random word from the 'words' list and convert it to uppercase\n",
        "easy_word = words[int(random() * len(words))].upper()\n",
        "easy_word_index = 0\n",
        "location = 0\n",
        "letter_help = 0"
      ],
      "metadata": {
        "id": "XOLh-Nkf_f6M"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def easy_mode(frame):\n",
        "    # Declare global variables\n",
        "    global cap, easy_word_user, easy_word, easy_word_index, curr_time, location, letter_help\n",
        "\n",
        "    def mediapipe_detection(image, model):\n",
        "        # Convert image color from BGR to RGB\n",
        "        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
        "        # Make predictions using the provided model\n",
        "        results = model.process(image)\n",
        "        # Convert the image color back from RGB to BGR\n",
        "        image = cv.cvtColor(image, cv.COLOR_RGB2BGR)\n",
        "        return image, results\n",
        "\n",
        "    def get_landmark_dist_test(results, x, y):\n",
        "        # Initialize an empty list to store landmark distances\n",
        "        hand_array = []\n",
        "        # Get the wrist position\n",
        "        wrist_pos = results.multi_hand_landmarks[0].landmark[0]\n",
        "        for result in results.multi_hand_landmarks[0].landmark:\n",
        "            # Calculate and append the scaled distances relative to the wrist\n",
        "            hand_array.append((result.x - wrist_pos.x) * (width / x))\n",
        "            hand_array.append((result.y - wrist_pos.y) * (height / y))\n",
        "        return hand_array[2:]\n",
        "\n",
        "    # Main function\n",
        "    # Get frame dimensions\n",
        "    width = int(cap.get(cv.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    # Set up the MediaPipe hands model\n",
        "    mp_hands = mp.solutions.hands\n",
        "    with mp_hands.Hands(min_detection_confidence=0.6, min_tracking_confidence=0.6, max_num_hands=1) as hands:\n",
        "        while cap.isOpened():\n",
        "            # Read a frame from the camera\n",
        "            ret, frame = cap.read()\n",
        "\n",
        "            try:\n",
        "                # Display the 'easy_word' on the frame\n",
        "                cv.putText(frame, easy_word, (int(width * 0.05), int(height * 0.95)), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 2, cv2.LINE_4)\n",
        "                # Display the 'easy_word_user' on the frame\n",
        "                cv.putText(frame, easy_word_user, (int(width * 0.05), int(height * 0.95)), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 2, cv2.LINE_4)\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "\n",
        "            # Make hand detections using MediaPipe\n",
        "            image, results = mediapipe_detection(frame, hands)\n",
        "\n",
        "            # Load an image of the letter corresponding to the current character in 'easy_word'\n",
        "            letter_help = cv2.resize(cv2.imread('easy_mode_letters/{}.png'.format(easy_word[easy_word_index].lower())), (0, 0), fx=0.2, fy=0.2)\n",
        "\n",
        "            # Find the bounding box of the detected hand\n",
        "            if results.multi_hand_landmarks:\n",
        "                x = [None, None]\n",
        "                y = [None, None]\n",
        "                for result in results.multi_hand_landmarks[0].landmark:\n",
        "                    if x[0] is None or result.x < x[0]:\n",
        "                        x[0] = result.x\n",
        "                    if x[1] is None or result.x > x[1]:\n",
        "                        x[1] = result.x\n",
        "\n",
        "                    if y[0] is None or result.y < y[0]:\n",
        "                        y[0] = result.y\n",
        "                    if y[1] is None or result.y > y[1]:\n",
        "                        y[1] = result.y\n",
        "\n",
        "                # Check if the current time is less than one-third of the time elapsed since the start\n",
        "                if curr_time < round((time.time() - start_time) / 3, 1) and x[0] is not None:\n",
        "                    curr_time = round((time.time() - start_time) / 3, 1)\n",
        "                    try:\n",
        "                        # Get landmark distances from a function\n",
        "                        test_image = get_landmark_dist_test(results, x[1] - x[0], y[1] - y[0])\n",
        "                        # Predict a class label using a machine learning classifier\n",
        "                        test_pred = np.argmax(clf.predict_proba(np.array([test_image])))\n",
        "                        test_probs = clf.predict_proba(np.array([test_image]))[0]\n",
        "                        print(\"Predicted:\", letters[test_pred], \", pred prob:\", max(test_probs), \", current index:\", easy_word_index, \", current time:\", curr_time)\n",
        "                        if max(test_probs) >= 0.8 or (max(test_probs) >= 0.6 and letters[test_pred] in ['p', 'r', 'u', 'v']):\n",
        "                            pred_letter = letters[test_pred].upper()\n",
        "                            if easy_word_index < len(easy_word) and pred_letter == easy_word[easy_word_index] and (easy_word_index == 0 or easy_word[easy_word_index] != easy_word[easy_word_index - 1]):\n",
        "                                easy_word_user += pred_letter\n",
        "                                easy_word_index += 1\n",
        "                                location = results.multi_hand_landmarks[0].landmark[0].x\n",
        "                            if easy_word_index < len(easy_word) and pred_letter == easy_word[easy_word_index] and easy_word_index > 0 and easy_word[easy_word_index] == easy_word[easy_word_index - 1] and abs(location - results.multi_hand_landmarks[0].landmark[0].x) > 0.1:\n",
        "                                easy_word_user += pred_letter\n",
        "                                easy_word_index += 1\n",
        "                                location = results.multi_hand_landmarks[0].landmark[0].x\n",
        "\n",
        "                        if easy_word_user == easy_word:\n",
        "                            time.sleep(0.5)\n",
        "                            # Select a new random word and reset variables\n",
        "                            easy_word = words[int(random() * len(words))].upper()\n",
        "                            easy_word_index = 0\n",
        "                            easy_word_user = ''\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(e)\n",
        "\n",
        "            # Show letter helper\n",
        "            frame[5:5 + letter_help.shape[0], width - 5 - letter_help.shape[1]:width - 5] = letter_help\n",
        "\n",
        "    return frame\n"
      ],
      "metadata": {
        "id": "udpIfFnL_f8e"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def medium_mode(frame):\n",
        "    global cap, easy_word_user, easy_word, easy_word_index, curr_time, location, letter_help\n",
        "\n",
        "    def mediapipe_detection(image, model):\n",
        "        # Convert image from BGR to RGB color format\n",
        "        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
        "        # Make predictions using the provided model\n",
        "        results = model.process(image)\n",
        "        # Convert the image back to BGR format\n",
        "        image = cv.cvtColor(image, cv.COLOR_RGB2BGR)\n",
        "        return image, results\n",
        "\n",
        "    def get_landmark_distances(results, x, y):\n",
        "        hand_array = []\n",
        "        wrist_pos = results.multi_hand_landmarks[0].landmark[0]\n",
        "        for result in results.multi_hand_landmarks[0].landmark:\n",
        "            hand_array.append((result.x - wrist_pos.x) * (width / x))\n",
        "            hand_array.append((result.y - wrist_pos.y) * (height / y))\n",
        "        return hand_array[2:]\n",
        "\n",
        "    # Main function\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    # Set up the MediaPipe hands model\n",
        "    mp_hands = mp.solutions.hands\n",
        "    with mp_hands.Hands(min_detection_confidence=0.6, min_tracking_confidence=0.6, max_num_hands=1) as hands:\n",
        "        while cap.isOpened():\n",
        "\n",
        "            # Read a frame from the camera\n",
        "            # ret, frame = cap.read()\n",
        "\n",
        "            try:\n",
        "                # Display the 'easy_word' and 'easy_word_user' on the frame\n",
        "                cv.putText(frame, easy_word, (int(width * 0.05), int(height * 0.95)), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 2, cv2.LINE_4)\n",
        "                cv.putText(frame, easy_word_user, (int(width * 0.05), int(height * 0.95)), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 2, cv2.LINE_4)\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "\n",
        "            # Make hand detections using MediaPipe\n",
        "            image, results = mediapipe_detection(frame, hands)\n",
        "\n",
        "            # Find the bounding box of the detected hand\n",
        "            if results.multi_hand_landmarks:\n",
        "                x = [None, None]\n",
        "                y = [None, None]\n",
        "                for result in results.multi_hand_landmarks[0].landmark:\n",
        "                    if x[0] is None or result.x < x[0]:\n",
        "                        x[0] = result.x\n",
        "                    if x[1] is None or result.x > x[1]:\n",
        "                        x[1] = result.x\n",
        "\n",
        "                    if y[0] is None or result.y < y[0]:\n",
        "                        y[0] = result.y\n",
        "                    if y[1] is None or result.y > y[1]:\n",
        "                        y[1] = result.y\n",
        "\n",
        "                # Check if the current time is less than one-third of the time elapsed since the start\n",
        "                if curr_time < round((time.time() - start_time) / 3, 1) and x[0] is not None:\n",
        "                    curr_time = round((time.time() - start_time) / 3, 1)\n",
        "                    try:\n",
        "                        # Get landmark distances from a function\n",
        "                        test_image = get_landmark_distances(results, x[1] - x[0], y[1] - y[0])\n",
        "\n",
        "                        # Predict a class label using a machine learning classifier\n",
        "                        test_pred = np.argmax(clf.predict_proba(np.array([test_image])))\n",
        "                        test_probs = clf.predict_proba(np.array([test_image]))[0]\n",
        "                        print(\"Predicted:\", letters[test_pred], \", pred prob:\", max(test_probs), \", current index:\", easy_word_index, \", current time:\", curr_time)\n",
        "                        if max(test_probs) >= 0.8 or (max(test_probs) >= 0.6 and letters[test_pred] in ['p', 'r', 'u', 'v']):\n",
        "                            pred_letter = letters[test_pred].upper()\n",
        "\n",
        "                            # Check if the predicted letter matches the expected letter in the word\n",
        "                            if easy_word_index < len(easy_word) and pred_letter == easy_word[easy_word_index] and (easy_word_index == 0 or easy_word[easy_word_index] != easy_word[easy_word_index - 1]):\n",
        "                                easy_word_user += pred_letter\n",
        "                                easy_word_index += 1\n",
        "                                location = results.multi_hand_landmarks[0].landmark[0].x\n",
        "                            if easy_word_index < len(easy_word) and pred_letter == easy_word[easy_word_index] and easy_word_index > 0 and easy_word[easy_word_index] == easy_word[easy_word_index - 1] and abs(location - results.multi_hand_landmarks[0].landmark[0].x) > 0.1:\n",
        "                                easy_word_user += pred_letter\n",
        "                                easy_word_index += 1\n",
        "                                location = results.multi_hand_landmarks[0].landmark[0].x\n",
        "\n",
        "                        if easy_word_user == easy_word:\n",
        "                            time.sleep(0.5)\n",
        "                            easy_word = words[int(random() * len(words))].upper()\n",
        "                            easy_word_index = 0\n",
        "                            easy_word_user = ''\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(e)\n",
        "\n",
        "            try:\n",
        "                # Check if 'letter_help' exists\n",
        "                letter_help == 0\n",
        "            except:\n",
        "                # If not, set a portion of the frame to be 'letter_help'\n",
        "                frame[5:5 + letter_help.shape[0], width - 5 - letter_help.shape[1]:width - 5] = frame[5:5 + letter_help.shape[0], width - 5 - letter_help.shape[1]:width - 5]\n",
        "\n",
        "            return frame\n",
        "\n",
        "    return frame\n"
      ],
      "metadata": {
        "id": "-O-2eRmY_f_K"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function named 'generate_frame' that generates frames from a camera stream.\n",
        "def generate_frame():\n",
        "    global easy_mode_enabled, medium_mode_enabled, camera\n",
        "\n",
        "    # Create an infinite loop to continuously capture frames.\n",
        "    while True:\n",
        "        # Capture a frame from the camera.\n",
        "        success, frame = camera.read()\n",
        "\n",
        "        if success:\n",
        "            if easy_mode_enabled:\n",
        "                # Process the frame using the 'easy_mode' function.\n",
        "                frame = process_easy_mode(frame)\n",
        "            elif medium_mode_enabled:\n",
        "                # Process the frame using the 'medium_mode' function.\n",
        "                frame = process_medium_mode(frame)\n",
        "\n",
        "            try:\n",
        "                # Encode the frame as a JPEG image.\n",
        "                ret, buffer = cv.imencode('.jpg', frame)\n",
        "                frame = buffer.tobytes()\n",
        "\n",
        "                # Yield the frame as a multipart HTTP response with the appropriate content type.\n",
        "                yield (b'--frame\\r\\n'\n",
        "                       b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')\n",
        "            except Exception as e:\n",
        "                pass\n"
      ],
      "metadata": {
        "id": "EBtZqKIa_gBj"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from flask import Flask, render_template, Response, request\n",
        "\n",
        "# Create a Flask web application\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Define the route for the homepage (\"/\")\n",
        "@app.route('/')\n",
        "def index():\n",
        "    # Render the \"index.html\" template and return it as a response\n",
        "    return render_template(\"index.html\")\n",
        "\n",
        "# Define the route for the video feed (\"/video_feed\")\n",
        "@app.route('/video_feed')\n",
        "def video_feed():\n",
        "    # Return a response that streams video frames using the \"sign_frame\" function\n",
        "    return Response(sign_frame(), mimetype='multipart/x-mixed-replace; boundary=frame')\n",
        "\n",
        "# Define the route for handling requests (\"/requests\") with POST and GET methods\n",
        "@app.route('/requests', methods=['POST', 'GET'])\n",
        "def mode():\n",
        "    # Define global variables for different modes and initialize them\n",
        "    global switch, easy_mode, medium_mode, hard_mode, free_mode\n",
        "    if request.method == 'POST':\n",
        "        # Check if the \"easy\" button was pressed\n",
        "        if request.form.get('easy') == 'Easy':\n",
        "            easy_mode = not easy_mode\n",
        "            medium_mode, hard_mode, free_mode = 0, 0, 0\n",
        "        # Check if the \"medium\" button was pressed\n",
        "        elif request.form.get('medium') == 'Medium':\n",
        "            medium_mode = not medium_mode\n",
        "            easy_mode, hard_mode, free_mode = 0, 0, 0\n",
        "        # Check if the \"hard\" button was pressed\n",
        "        elif request.form.get('hard') == 'Hard':\n",
        "            hard_mode = not hard_mode\n",
        "            easy_mode, medium_mode, free_mode = 0, 0, 0\n",
        "        # Check if the \"freestyle\" button was pressed\n",
        "        elif request.form.get('free') == 'Freestyle':\n",
        "            free_mode = not free_mode\n",
        "            easy_mode, medium_mode, hard_mode = 0, 0, 0\n",
        "\n",
        "    elif request.method == 'GET':\n",
        "        # Render the \"index.html\" template for GET requests\n",
        "        return render_template('index.html')\n",
        "\n",
        "    # Always render the \"index.html\" template to display the current mode\n",
        "    return render_template('index.html')\n",
        "\n",
        "# Run the Flask application if this script is executed\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvTXK23L_gD_",
        "outputId": "e294f935-60f7-4f8c-ee28-32c75d572325"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with stat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BQVy3Yax_gId"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}