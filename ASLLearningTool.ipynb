{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/annbinus/ASLExpress/blob/akhila's-branch/ASLLearningTool.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "LLuc7hRlbDyK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "975403e7-8514-48e4-e523-41e612135dd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.10/dist-packages (0.10.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.1.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.5.26)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.23.5)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.8.0.76)\n",
            "Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.20.3)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.6)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.15.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "#pip install --upgrade mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install english-words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wm6altGtw1e8",
        "outputId": "f17be3c0-f8cc-429d-e74c-6ee277c58798"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: english-words in /usr/local/lib/python3.10/dist-packages (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Import the OpenCV library for computer vision tasks.\n",
        "import cv2 as cv\n",
        "\n",
        "# Import the Mediapipe library for various computer vision and machine learning tasks.\n",
        "import mediapipe as mp\n",
        "\n",
        "# Import the joblib library for saving and loading machine learning models.\n",
        "import joblib\n",
        "\n",
        "# Import the time module for time-related operations or measurements.\n",
        "import time\n",
        "\n",
        "# Import the os and sys modules for operating system and system-related functions.\n",
        "import os, sys"
      ],
      "metadata": {
        "id": "3rTkQzRlmDf3"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from random import random"
      ],
      "metadata": {
        "id": "Ai2_cJ2LpfiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the function 'get_english_words_set' from the 'english_words' library.\n",
        "from english_words import get_english_words_set\n",
        "\n",
        "# Create a set of English words from the 'web2' dataset in lowercase.\n",
        "# The 'get_english_words_set' function is used with the 'lower' parameter set to 'True'\n",
        "# to ensure that the words are converted to lowercase.\n",
        "web2lowerset = get_english_words_set(['web2'], lower=True)"
      ],
      "metadata": {
        "id": "u8owAuRRqD7k"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary modules from the Flask framework\n",
        "from flask import Flask           # Flask is used to create the web application instance.\n",
        "from flask import render_template # render_template is used to render HTML templates.\n",
        "from flask import Response        # Response is used to create HTTP responses.\n",
        "from flask import request         # request is used to access data sent with HTTP requests."
      ],
      "metadata": {
        "id": "kMDiPqf6qGiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Global Variables for Game Difficulty and Mode\n",
        "global easy, medium, hard, freestyle, switch\n",
        "level1 = 0        # Represents the easy game mode.\n",
        "level2 = 0      # Represents the medium game mode.\n",
        "level3 = 0        # Represents the hard game mode.\n",
        "freestyle = 0   # Represents the freestyle game mode."
      ],
      "metadata": {
        "id": "phGTAZ-6rnVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a pre-trained machine learning model (Random Forest Classifier) from a file named \"random_forest.joblib\"\n",
        "clf = joblib.load(\"/content/random_forest.joblib\")"
      ],
      "metadata": {
        "id": "7DK8wJbcrnXl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd3cd256-ebac-4fa1-9a68-d6c0fca24e57"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.24.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.24.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "app = Flask(__name__, template_folder='./template')"
      ],
      "metadata": {
        "id": "x4j8pW7evA1o"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to perform object detection using a provided model.\n",
        "# Args:\n",
        "#   image (numpy.ndarray): Input image in BGR format.\n",
        "#   model: A pre-trained machine learning model (e.g., Mediapipe model).\n",
        "# Returns:\n",
        "#   image (numpy.ndarray): Processed image in BGR format.\n",
        "#   results: Detection results from the model.\n",
        "def mediapipe_detection(image, model):\n",
        "    # Convert the input image from BGR to RGB color space.\n",
        "    image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
        "\n",
        "    # Make predictions using the provided model.\n",
        "    final_results = model.process(image)\n",
        "\n",
        "    # Convert the processed image from RGB back to BGR color space.\n",
        "    image = cv.cvtColor(image, cv.COLOR_RGB2BGR)\n",
        "\n",
        "    # Return the processed image and detection results.\n",
        "    return image, final_results"
      ],
      "metadata": {
        "id": "GgtWaNnvywgS"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate and return the normalized landmark distances relative to the wrist position.\n",
        "# Args:\n",
        "#   results: Detection results containing hand landmarks.\n",
        "#   frame_width (int): Width of the frame or image.\n",
        "#   frame_height (int): Height of the frame or image.\n",
        "# Returns:\n",
        "#   normalized_landmark_distances (list): List of normalized landmark distances (x and y coordinates).\n",
        "def get_normalized_landmark_distances(results, frame_width, frame_height):\n",
        "    normalized_landmark_distances = []  # Initialize an empty list to store normalized landmark distances.\n",
        "\n",
        "    # Get the wrist position (the reference point) of the detected hand.\n",
        "    wrist_position = results.multi_hand_landmarks[0].landmark[0]\n",
        "\n",
        "    # Calculate and normalize the distances of each landmark relative to the wrist position.\n",
        "    for landmark in results.multi_hand_landmarks[0].landmark:\n",
        "        # Calculate and normalize the x and y distances based on the frame width and height.\n",
        "        normalized_x = (landmark.x - wrist_position.x) * (frame_width / frame_width)\n",
        "        normalized_y = (landmark.y - wrist_position.y) * (frame_height / frame_height)\n",
        "\n",
        "        # Append the normalized distances to the normalized_landmark_distances list.\n",
        "        normalized_landmark_distances.append(normalized_x)\n",
        "        normalized_landmark_distances.append(normalized_y)\n",
        "\n",
        "    # Return the list of normalized landmark distances, excluding the wrist position (first two values).\n",
        "    return normalized_landmark_distances[2:]\n"
      ],
      "metadata": {
        "id": "M51vWTeBywlA"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to determine the maximum available camera index connected to the host device.\n",
        "# Returns the maximum camera index as an integer.\n",
        "\n",
        "def camera_max():\n",
        "    camera_index = 0  # Initialize the camera index to 0.\n",
        "\n",
        "    while True:\n",
        "        # Check if the camera with the current index can be accessed.\n",
        "        if cv.VideoCapture(camera_index).grab():\n",
        "            camera_index += 1\n",
        "        else:\n",
        "            # Close any open windows and return the maximum camera index (camera_index - 1).\n",
        "            cv.destroyAllWindows()\n",
        "            return max(0, int(camera_index - 1))\n"
      ],
      "metadata": {
        "id": "m8OJMHynywny"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list of words that are sorted, not containing 'z', have a length between 4 and 10 characters.\n",
        "words = [word for word in sorted(list(web2lowerset)) if 'z' not in word and 3 < len(word) <= 10]\n",
        "\n",
        "# Initialize some variables\n",
        "start_time = time.time()\n",
        "curr_time = 0\n",
        "user_input_word = ''\n",
        "eraser = 0\n",
        "\n",
        "# Choose a random word from the 'words' list and convert it to uppercase\n",
        "random_word = words[int(random() * len(words))].upper()\n",
        "random_word_index = 0\n",
        "\n",
        "# Create a list of lowercase letters\n",
        "letters = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
        "\n",
        "# Initialize video capture using the maximum available camera\n",
        "cap = cv.VideoCapture(camera_max())\n",
        "width = int(cap.get(cv.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "# Set up the MediaPipe hands model\n",
        "mp_hands = mp.solutions.hands\n",
        "with mp_hands.Hands(min_detection_confidence=0.6, min_tracking_confidence=0.6, max_num_hands=1) as hands:\n",
        "    while cap.isOpened():\n",
        "        # Read a frame from the camera\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "        try:\n",
        "            # Display the 'random_word' on the frame\n",
        "            cv.putText(frame, random_word, (int(width * 0.05), int(height * 0.95)), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 2, cv2.LINE_4)\n",
        "\n",
        "            # Display the 'user_input_word' on the frame\n",
        "            cv.putText(frame, user_input_word, (int(width * 0.05), int(height * 0.95)), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 2, cv2.LINE_4)\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "\n",
        "        # Make hand detections using MediaPipe\n",
        "        image, results = mediapipe_detection(frame, hands)\n",
        "\n",
        "        # Load an image of the letter corresponding to the current character in 'random_word'\n",
        "        letter_image = cv.resize(cv.imread('easy_mode_letters/{}.png'.format(random_word[random_word_index].lower())), (0, 0), fx=0.2, fy=0.2)\n",
        "\n",
        "        # Find the bounding box of the detected hand\n",
        "        if results.multi_hand_landmarks:\n",
        "            x = [None, None]\n",
        "            y = [None, None]\n",
        "            for result in results.multi_hand_landmarks[0].landmark:\n",
        "                if x[0] is None or result.x < x[0]: x[0] = result.x\n",
        "                if x[1] is None or result.x > x[1]: x[1] = result.x\n",
        "\n",
        "                if y[0] is None or result.y < y[0]: y[0] = result.y\n",
        "                if y[1] is None or result.y > y[1]: y[1] = result.y\n"
      ],
      "metadata": {
        "id": "k0ei91Flywqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize variables\n",
        "curr_time = 0.0  # Current time\n",
        "start_time = time.time()  # Record the start time\n",
        "easy_word_user = ''  # Initialize a variable to store user input\n",
        "easy_word_index = 0  # Initialize an index to keep track of the letters in the word\n",
        "location = 0.0  # Initialize a variable to store the location of a hand landmark\n",
        "\n",
        "# Main loop to process video frames\n",
        "while True:\n",
        "    # Check if the current time is less than one-third of the time elapsed since the start\n",
        "    if curr_time < round((time.time() - start_time) / 3, 1):\n",
        "        # Update current time with one-third of the elapsed time\n",
        "        curr_time = round((time.time() - start_time) / 3, 1)\n",
        "\n",
        "        # Check if the first element of x is not None\n",
        "        if x[0] is not None:\n",
        "            try:\n",
        "                # Get landmark distances from a function\n",
        "                test_image = get_landmark_dist_test(results, x[1] - x[0], y[1] - y[0])\n",
        "\n",
        "                # Predict a class label using a machine learning classifier\n",
        "                test_pred = np.argmax(clf.predict_proba(np.array([test_image])))\n",
        "                test_probs = clf.predict_proba(np.array([test_image]))[0]\n",
        "\n",
        "                # Check if the maximum predicted probability is above a threshold or\n",
        "                # if it's moderately high and the predicted letter is 'r' or 'v'\n",
        "                if max(test_probs) >= 0.8 or (max(test_probs) >= 0.6 and letters[test_pred] in ['r', 'v']):\n",
        "                    pred_letter = letters[test_pred].upper()\n",
        "\n",
        "                    # Check if the predicted letter matches the expected letter in the word\n",
        "                    if easy_word_index < len(easy_word) and pred_letter == easy_word[easy_word_index] and (easy_word_index == 0 or easy_word[easy_word_index] != easy_word[easy_word_index - 1]):\n",
        "                        easy_word_user += pred_letter\n",
        "                        easy_word_index += 1\n",
        "                        location = results.multi_hand_landmarks[0].landmark[0].x\n",
        "\n",
        "                    # Check if the predicted letter matches the expected letter,\n",
        "                    # and if the previous and current letters are the same,\n",
        "                    # and if the hand location has changed significantly\n",
        "                    if easy_word_index < len(easy_word) and pred_letter == easy_word[easy_word_index] and easy_word_index > 0 and easy_word[easy_word_index] == easy_word[easy_word_index - 1] and abs(location - results.multi_hand_landmarks[0].landmark[0].x) > 0.1:\n",
        "                        easy_word_user += pred_letter\n",
        "                        easy_word_index += 1\n",
        "                        location = results.multi_hand_landmarks[0].landmark[0].x\n",
        "\n",
        "                # Check if the user has correctly spelled the word\n",
        "                if easy_word_user == easy_word:\n",
        "                    time.sleep(0.5)\n",
        "                    # Select a new random word and reset variables\n",
        "                    easy_word = words[int(random() * len(words))].upper()\n",
        "                    easy_word_index = 0\n",
        "                    easy_word_user = ''\n",
        "\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "\n",
        "    # Display an image on the screen\n",
        "    frame[5:5 + letter_help.shape[0], width - 5 - letter_help.shape[1]:width - 5] = letter_help\n",
        "    cv2.imshow('OpenCV Feed', frame)\n",
        "\n",
        "    # Break the loop if the user presses the 'Esc' key\n",
        "    key = cv2.waitKey(20)\n",
        "    if key == 27:\n",
        "        break\n",
        "\n",
        "# Release the video capture and close all OpenCV windows\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "jDBZ9Yn_7ZOC",
        "outputId": "a43e6c0d-4e5d-4694-8774-57ca9c473999"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-6f6e36b3836d>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# Display an image on the screen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mletter_help\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mletter_help\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mwidth\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mletter_help\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'OpenCV Feed'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'letter_help' is not defined"
          ]
        }
      ]
    }
  ]
}